<!doctype html>
<html>
<head>
<meta http-equiv='Content-Type' content='text/html; charset=UTF-8'>
<title> webrtc demo  </title>
<style type="text/css">
	.room {
		cursor: pointer;
	}
	div.select {
      display: inline-block;
      margin: 0 0 1em 0;
    }
    #c {
        width: 960px;
        height: 540px;
    }
</style>

<script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
<script src="/public/fabric.min.js"></script>
</head>
<body>
	<h1>MediaServer  Demo</h1>
	<br/>

	<div id="conference">
		videos:
		<br />
		<div id="container">
            <video muted width="960" height="540" id="webcam" style="display: none">
            </video>
        </div>
    </div>
    <div id="container">
        <canvas id="c" width="960" height="540" style="border:1px solid #ccc"></canvas>
    </div>
    <script>
        window.localStorage.setItem('debug', '*');

        let container;
        var socket;
        var canvas;
        function addVideoForStream(stream,muted)
        {
            //Create new video element
            const video = document.createElement("video");
            //Set same id
            video.id = stream.id;
            video.width = 960;
            video.height = 540;
            //Set src stream
            video.srcObject = stream;
            //Set other properties
            video.autoplay = true;
            video.muted = muted;


            container.appendChild(video);
        }

        document.addEventListener('DOMContentLoaded', function(e) {
            
            container = document.getElementById('container');

            canvas = new fabric.Canvas('c');
            canvas.setDimensions({width: 960, height: 540})
            setInterval(() => {
                canvas.renderAll();
            }, 30);
            // fabric.util.requestAnimFrame(function render() {
            //     canvas.renderAll();
            //     fabric.util.requestAnimFrame(render);
            // });
            (async () => {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: true,
                    video: {width: 1280, height: 720}
                });

                //addVideoForStream(stream, true)

                var video1El = document.getElementById('webcam');
                
                var video1 = new fabric.Image(video1El, {
                    left: canvas.width/2,
                    top: canvas.height/2,
                    angle: 0,
                    originX: 'center',
                    originY: 'center',
                    objectCaching: false,
                });

                var v = document.getElementById('webcam');
                v.srcObject = stream
                canvas.add(video1)
                video1.moveTo(0)
                video1.getElement().play()
                // canvas.calcOffset()
                setTimeout(() => {
                var pc = new RTCPeerConnection();
        
                pc.onaddstream = function(event) {
                    console.debug("pc::onAddStream",event);
                    //Play it
                    addVideoForStream(event.stream,true);
                };
                
                pc.onremovestream = function(event) {
                    console.debug("pc::onRemoveStream",event);
                    //Play it
                    removeVideoForStream(event.stream);
                };
                let domain = window.location.origin.replace('http', 'ws')
                if (window.location.protocol === 'https') {
                    domain = window.location.origin.replace('https', 'wss')
                }
                socket = new WebSocket(domain + '/channel');
                
                socket.onopen = async () => {
                    const mixedCanvas = canvas.lowerCanvasEl;
                    const mixedStream = mixedCanvas.captureStream(30);
                    const audioTrack = v.srcObject.getAudioTracks()[0]

                    mixedStream.addTrack(audioTrack)
                    console.debug("md::getUserMedia sucess",stream);
        
                    mixedStream.getTracks().forEach(function(track) {
                        pc.addTrack(track, mixedStream);
                    });

                    //Create new offer
                    const offer = await pc.createOffer({
                        offerToReceiveAudio: true,
                        offerToReceiveVideo: true
                    });
                    //Set it
                    
                    pc.setLocalDescription(offer);
                    
                    console.log("offer ==== ",offer.sdp);
                    socket.send(JSON.stringify({
                        cmd: 'offer',
                        sdp: offer.sdp
                    }));
                };

                socket.onmessage  = async (event) =>{
                    var data = JSON.parse(event.data);
                    console.log(data);

                    if (data.sdp) {
                        //Create answer
                        const answer = new RTCSessionDescription({
                            type	:'answer',
                            sdp	: data.sdp
                        }); 
                        console.debug(answer.sdp);
                        await pc.setRemoteDescription(answer); 
                    }
                };
            }, 10000)
            })()
        })
    </script>
</body>

</html>